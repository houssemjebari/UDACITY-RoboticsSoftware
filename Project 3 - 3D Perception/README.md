![demo-1](https://user-images.githubusercontent.com/20687560/28748231-46b5b912-7467-11e7-8778-3095172b7b19.png)

# 3D Perception

In this project we focus on 3D perception of the PR2 robot simulated in Gazebo.

The PR2 has been outfitted with an RGB-D sensor. This sensor however is a bit noisy, much like real sensors.

The robot is provided with a pick list which indicates which objects to pick from the cluttered table, in which order to pick them and where to place them.

## 1 - Perception Pipeline
In This project I have implemented the software stack for the PR2 robot through processing point clouds generated by the RGB-D camera.
the code for the pipeline can be checked at 
```sh
pr2_robot/scripts/recognition.py
``` 
### **Filtering and RANSAC plane fitting**
During this first stage of input data cloud processing the following processes were applied:
* Statistical outlier removal
* Voxel grid downsampling
* Pass through filtering
* Plane fitting using RANSAC


the following images shows the output of these steps where we have point clouds of objects of interest only.

[image_1]: ./misc_images/ransac.PNG

![alt text][image_1] 


### **Clustering**
the resulted point cloud can be used as input to the **DBSCAN**
clustering algorithm to cluster each object alone.

[image_2]: ./misc_images/euclidean_clustering.png

![alt text][image_2] 

### **Object Classification**
We can then train an **SVM** classifier to recognize each object in the scene.

the classifier can be trained with the following commands each in a terminal 
```sh
$catkin_ws/ roslaunch   pr2_robot   training.launch
``` 
```sh
$catkin_ws/ rosrun  sensor_stick    capture_features.py     
``` 
```sh
$catkin_ws/ rosrun  sensor_stick    train_svm.py     
``` 
after training successfully a confusion matrix is outputted to analyze the results and for further tuning.

[image_3]: ./misc_images/heatmap.png

![alt text][image_3] 


## 3 - Launching the project

For this setup, catkin_ws is the name of active ROS Workspace, if your workspace name is different, change the commands accordingly
If you do not have an active ROS workspace, you can create one by:

```sh
$ mkdir -p ~/catkin_ws/src
$ cd ~/catkin_ws/
$ catkin_make
```
 install missing dependencies using rosdep install:
```sh
$ cd ~/catkin_ws
$ rosdep install --from-paths src --ignore-src --rosdistro=kinetic -y
```
Build the project:
```sh
$ cd ~/catkin_ws
$ catkin_make
```
Add following to your .bashrc file
```
export GAZEBO_MODEL_PATH=~/catkin_ws/src/pr2_robot/models:$GAZEBO_MODEL_PATH
```

If you havenâ€™t already, following line can be added to your .bashrc to auto-source all new terminals
```
source ~/catkin_ws/devel/setup.bash
```

Finally to run the project 
```sh
$catkin_ws/ roslaunch     pr2_robot   pick_place_project.launch   
```
```sh
$catkin_ws/ rosrun     pr2_robot    recognition.py   
```

